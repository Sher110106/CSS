================================================================================
                    üöÄ START HERE - OVERNIGHT DATA COLLECTION üöÄ
================================================================================

Hi! I've created a robust overnight data collection system for your project.
Here's everything you need to get started.

================================================================================
üìã WHAT YOU NEED TO DO (3 SIMPLE STEPS)
================================================================================

STEP 1: Check Your Reddit Credentials (2 minutes)
------------------------------------------------
Open: .env (in this directory)

Make sure it contains:
  REDDIT_CLIENT_ID=your_actual_client_id
  REDDIT_CLIENT_SECRET=your_actual_secret
  REDDIT_USER_AGENT=semaglutide_research_v1.0

Don't have credentials yet?
  ‚Üí Go to: https://www.reddit.com/prefs/apps
  ‚Üí Click "Create App"
  ‚Üí Choose "script" type
  ‚Üí Copy client_id and secret to .env


STEP 2: Test Collection (3 minutes)
----------------------------------
Run this command:

  python scripts/test_collection.py

This will collect ~50 posts to verify everything works.

Expected output:
  ‚úÖ TEST PASSED - Collection system working!

If it fails:
  ‚Üí Check your .env credentials
  ‚Üí Make sure you have internet
  ‚Üí See TROUBLESHOOTING section below


STEP 3: Run Overnight Collection (8-12 hours)
--------------------------------------------
Run this command:

  python scripts/run_overnight_collection.py

Follow the prompts:
  - Enter target posts (try 10000 first)
  - Enter max hours (try 8-10 hours)
  - Press Enter to start

Then let it run! You can:
  ‚úì Close this terminal (if on local machine)
  ‚úì Press Ctrl+C anytime to stop gracefully
  ‚úì Resume later with: --resume flag

================================================================================
üìÅ WHAT WAS CREATED FOR YOU
================================================================================

Main Scripts:
  ‚úì scripts/01_data_collection_overnight.py  - Enhanced scraper
  ‚úì scripts/run_overnight_collection.py      - Easy runner
  ‚úì scripts/test_collection.py               - Quick test

Documentation:
  ‚úì QUICK_START.md                - Quick reference (1 page)
  ‚úì OVERNIGHT_COLLECTION_GUIDE.md - Complete guide (detailed)
  ‚úì EXECUTION_INSTRUCTIONS.txt    - Step-by-step instructions
  ‚úì This file (RUN_ME_FIRST.txt)  - You are here!

================================================================================
üéØ KEY FEATURES OF YOUR NEW SYSTEM
================================================================================

‚úÖ Robust Error Handling
   - Automatically recovers from API errors
   - Handles rate limits gracefully
   - Retries failed requests

‚úÖ Checkpoint System
   - Auto-saves every 5 minutes
   - Resume after interruption
   - No data loss

‚úÖ Adaptive Rate Limiting
   - Adjusts speed to avoid limits
   - Maximizes collection rate
   - Respects Reddit's API rules

‚úÖ Multiple Collection Strategies
   - Uses search, hot, top, new methods
   - Maximizes unique posts
   - Better coverage

‚úÖ Comprehensive Logging
   - Tracks every step
   - Helps with debugging
   - Progress monitoring

================================================================================
‚ö° QUICK COMMAND REFERENCE
================================================================================

Test (do this first!):
  python scripts/test_collection.py

Standard run (10k posts, 8 hours):
  python scripts/run_overnight_collection.py

Large collection (20k posts, 12 hours):
  python scripts/run_overnight_collection.py --target 20000 --hours 12

Resume after interruption:
  python scripts/run_overnight_collection.py --resume

Skip confirmation and start immediately:
  python scripts/run_overnight_collection.py --no-confirm

Quick test (100 posts, 30 min):
  python scripts/run_overnight_collection.py --target 100 --hours 0.5

================================================================================
üìä WHAT TO EXPECT
================================================================================

Collection Speed:
  ‚Ä¢ Typical: 20-50 posts per hour
  ‚Ä¢ Fast: 50-100 posts per hour
  ‚Ä¢ Slow: 5-20 posts per hour (rate limiting)

Time Estimates:
  ‚Ä¢ 1,000 posts:   1-2 hours
  ‚Ä¢ 5,000 posts:   2-5 hours
  ‚Ä¢ 10,000 posts:  4-8 hours
  ‚Ä¢ 20,000 posts:  8-16 hours

Output Files:
  ‚Ä¢ data/raw/posts.csv              - All collected posts
  ‚Ä¢ data/raw/comments.csv           - All collected comments
  ‚Ä¢ logs/overnight_collection_*.log - Detailed execution log

================================================================================
üõë HOW TO STOP
================================================================================

Graceful Stop:
  1. Press Ctrl+C ONCE
  2. Wait for "Saving progress..." message
  3. Data will be saved automatically

Resume Later:
  python scripts/run_overnight_collection.py --resume

Note: Data is auto-saved every 5 minutes anyway!

================================================================================
üîç MONITORING PROGRESS
================================================================================

While Running:
  ‚Üí Console shows progress every 5 minutes
  ‚Üí Check log: tail -f logs/overnight_collection_*.log
  ‚Üí Count posts: wc -l data/raw/posts_checkpoint.csv

After Completion:
  ‚Üí Check data/raw/posts.csv
  ‚Üí Check data/raw/comments.csv
  ‚Üí Read data/metadata/overnight_collection_report.json

================================================================================
‚ö†Ô∏è TROUBLESHOOTING
================================================================================

Problem: "Authentication failed"
  ‚Üí Check .env has correct Reddit credentials
  ‚Üí Verify at: https://www.reddit.com/prefs/apps
  ‚Üí Make sure app type is "script"

Problem: "Rate limit exceeded" messages
  ‚Üí This is NORMAL - script handles it automatically
  ‚Üí Just let it run, it will slow down and recover

Problem: Very slow (<5 posts/hour)
  ‚Üí Edit config/config.yaml to add more keywords
  ‚Üí Add more subreddits
  ‚Üí Try running during off-peak hours (US nighttime)

Problem: Script seems stuck
  ‚Üí Check the log file for activity
  ‚Üí If no activity for 10+ min, Ctrl+C and restart
  ‚Üí Use --resume to continue

Problem: Test fails
  ‚Üí Verify internet connection
  ‚Üí Check Reddit credentials in .env
  ‚Üí Try again in a few minutes (Reddit may be slow)

================================================================================
üìö NEED MORE HELP?
================================================================================

Quick reference:
  ‚Üí See QUICK_START.md (1 page cheat sheet)

Detailed guide:
  ‚Üí See OVERNIGHT_COLLECTION_GUIDE.md (comprehensive FAQ)

Step-by-step:
  ‚Üí See EXECUTION_INSTRUCTIONS.txt (detailed walkthrough)

Check Reddit status:
  ‚Üí Visit: https://www.redditstatus.com

================================================================================
‚úÖ PRE-FLIGHT CHECKLIST
================================================================================

Before starting overnight collection:

  [ ] Reddit credentials in .env file
  [ ] Ran test_collection.py successfully
  [ ] Have stable internet connection
  [ ] Computer won't sleep/shutdown during run
  [ ] Sufficient disk space (500MB+ recommended)
  [ ] Know where log files are (logs/ directory)
  [ ] Understand how to stop (Ctrl+C once)

================================================================================
üéì TIPS FOR BEST RESULTS
================================================================================

1. Always test first
   ‚Üí Run test_collection.py before overnight run
   ‚Üí Catches issues early

2. Start moderate
   ‚Üí First run: aim for 5,000-10,000 posts
   ‚Üí Scale up after you see how it performs

3. Monitor first hour
   ‚Üí Check logs after 30-60 minutes
   ‚Üí Verify collection is working
   ‚Üí Adjust if needed

4. Run during off-peak
   ‚Üí Best: US nighttime (midnight-8am Eastern)
   ‚Üí Reddit API is faster

5. Use screen/tmux for servers
   ‚Üí screen -S reddit
   ‚Üí Run collection
   ‚Üí Ctrl+A, D to detach
   ‚Üí screen -r reddit to reattach

6. Backup your data
   ‚Üí After successful runs
   ‚Üí Copy data/raw to safe location

================================================================================
üöÄ READY TO START?
================================================================================

Quick Start Commands:

  cd /Users/sher/project/css/semaglutide-reddit-analysis
  
  # If using virtual environment:
  source venv/bin/activate
  
  # Test first (IMPORTANT!):
  python scripts/test_collection.py
  
  # Run overnight collection:
  python scripts/run_overnight_collection.py

That's it! Follow the prompts and let it run.

================================================================================
üìà WHAT HAPPENS NEXT?
================================================================================

After collection completes successfully, you'll have:

  ‚úì data/raw/posts.csv      - Thousands of Reddit posts
  ‚úì data/raw/comments.csv   - Tens of thousands of comments
  ‚úì Rich dataset ready for analysis

Next steps in your project:
  1. Preprocessing: python scripts/02_data_preprocessing.py
  2. EDA: python scripts/03_exploratory_analysis.py
  3. Topic Modeling: python scripts/04_topic_modeling.py
  4. Sentiment Analysis: python scripts/05_sentiment_analysis.py
  5. Visualization: python scripts/07_visualization.py
  6. Report Generation: python scripts/08_report_generation.py

================================================================================

Questions? Check the documentation files or see the troubleshooting section.

Good luck with your data collection! üéâ

================================================================================
